from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferWindowMemory
from dotenv import find_dotenv,load_dotenv
import requests
import os
from huggingface_hub import hf_hub_download
from langchain_community.llms import HuggingFaceEndpoint
from transformers import AutoModel
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM

access_token = "API_KEY"
model_id = AutoModel.from_pretrained("teknium/OpenHermes-2.5-Mistral-7B", token=access_token)
tokenizer = AutoTokenizer.from_pretrained(model_id, legacy=False)
model = AutoModelForSeq2SeqLM.from_pretrained(model_id)
